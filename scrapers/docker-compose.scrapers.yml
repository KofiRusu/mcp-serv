# =============================================================================
# ChatOS Trading Scrapers - Docker Compose (Extended)
# 24/7 data collection for market data, news, sentiment, and derivatives
# =============================================================================
#
# Usage:
#   docker-compose -f docker-compose.scrapers.yml up -d     # Start all scrapers
#   docker-compose -f docker-compose.scrapers.yml down      # Stop all scrapers
#   docker-compose -f docker-compose.scrapers.yml logs -f   # View logs
#
# Individual services:
#   docker-compose -f docker-compose.scrapers.yml up -d aggr-agent
#   docker-compose -f docker-compose.scrapers.yml up -d coinglass-agent
#
# =============================================================================

version: '3.8'

services:
  # ===========================================================================
  # Market Data Scraper
  # Collects: tickers, order books, trades, OHLCV candles
  # ===========================================================================
  market-scraper:
    build:
      context: ..
      dockerfile: scrapers/Dockerfile.scraper
    container_name: chatos-market-scraper
    restart: always
    volumes:
      - ../sandbox-ui/data/market-history:/app/data/market-history
      - scraper-logs:/app/logs
    environment:
      - SCRAPER_TYPE=market
      - SYMBOLS=BTCUSDT,ETHUSDT,SOLUSDT,BNBUSDT,XRPUSDT,ADAUSDT
      - INTERVAL_SECONDS=30
      - PYTHONUNBUFFERED=1
    command: python -u market_scraper.py
    healthcheck:
      test: ["CMD", "python", "-c", "import os; exit(0 if os.path.exists('/app/data/market-history') else 1)"]
      interval: 60s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # News Scraper
  # Collects: crypto news from various sources
  # ===========================================================================
  news-scraper:
    build:
      context: ..
      dockerfile: scrapers/Dockerfile.scraper
    container_name: chatos-news-scraper
    restart: always
    volumes:
      - ../sandbox-ui/data/news:/app/data/news
      - scraper-logs:/app/logs
    environment:
      - SCRAPER_TYPE=news
      - INTERVAL_SECONDS=300
      - PYTHONUNBUFFERED=1
    command: python -u news_scraper.py
    healthcheck:
      test: ["CMD", "python", "-c", "import os; exit(0 if os.path.exists('/app/data/news') else 1)"]
      interval: 300s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # Sentiment Scraper
  # Collects: Fear & Greed index, market sentiment, funding rates
  # ===========================================================================
  sentiment-scraper:
    build:
      context: ..
      dockerfile: scrapers/Dockerfile.scraper
    container_name: chatos-sentiment-scraper
    restart: always
    volumes:
      - ../sandbox-ui/data/sentiment:/app/data/sentiment
      - scraper-logs:/app/logs
    environment:
      - SCRAPER_TYPE=sentiment
      - INTERVAL_SECONDS=600
      - PYTHONUNBUFFERED=1
    command: python -u sentiment_scraper.py
    healthcheck:
      test: ["CMD", "python", "-c", "import os; exit(0 if os.path.exists('/app/data/sentiment') else 1)"]
      interval: 300s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # AGGR Agent (L1 Market Microstructure)
  # Real-time aggregated trades via WebSocket
  # Similar to aggr.trade functionality
  # ===========================================================================
  aggr-agent:
    build:
      context: ..
      dockerfile: scrapers/Dockerfile.scraper
    container_name: chatos-aggr-agent
    restart: always
    volumes:
      - ../sandbox-ui/data/aggr:/app/data/aggr
      - scraper-logs:/app/logs
    environment:
      - SCRAPER_TYPE=aggr
      - SYMBOLS=BTCUSDT,ETHUSDT,SOLUSDT
      - INTERVAL_SECONDS=1
      - PYTHONUNBUFFERED=1
    command: python -u aggr_scraper.py
    healthcheck:
      test: ["CMD", "python", "-c", "import os; exit(0 if os.path.exists('/app/data/aggr') else 1)"]
      interval: 60s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # CoinGlass Heatmap Agent (L1 Market Microstructure)
  # Collects: liquidations, open interest, long/short ratios, heatmaps
  # ===========================================================================
  coinglass-agent:
    build:
      context: ..
      dockerfile: scrapers/Dockerfile.scraper
    container_name: chatos-coinglass-agent
    restart: always
    volumes:
      - ../sandbox-ui/data/coinglass:/app/data/coinglass
      - scraper-logs:/app/logs
    environment:
      - SCRAPER_TYPE=coinglass
      - SYMBOLS=BTC,ETH,SOL
      - INTERVAL_SECONDS=60
      - PYTHONUNBUFFERED=1
    command: python -u coinglass_scraper.py
    healthcheck:
      test: ["CMD", "python", "-c", "import os; exit(0 if os.path.exists('/app/data/coinglass') else 1)"]
      interval: 120s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # Footprint Charts Agent (L1 Market Microstructure) - PLANNED
  # Collects: volume profile, order flow, footprint candles
  # Note: Requires additional implementation for bid/ask volume tracking
  # ===========================================================================
  # footprint-agent:
  #   build:
  #     context: ..
  #     dockerfile: scrapers/Dockerfile.scraper
  #   container_name: chatos-footprint-agent
  #   restart: always
  #   volumes:
  #     - ../sandbox-ui/data/footprint:/app/data/footprint
  #     - scraper-logs:/app/logs
  #   environment:
  #     - SCRAPER_TYPE=footprint
  #     - SYMBOLS=BTCUSDT,ETHUSDT
  #     - PYTHONUNBUFFERED=1
  #   command: python -u footprint_scraper.py

volumes:
  scraper-logs:
    name: chatos-scraper-logs

networks:
  default:
    name: chatos-scrapers-network
